{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPx8EZ/cYkNnLuK6dJS7PRn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MittalMonika/DataScience/blob/master/yolo_Sign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SignaTech: Revolutionizing Document Processing with Advanced OCR and AI-Driven Signature Detection**\n",
        "\n",
        "Below is brief outline of the steps that need to be executed for the workflow\n",
        "\n",
        "1. Read document (pdf) from a given location.\n",
        "2. Split the document into pages and covert each page into png/jpg format and save with appropriate naming convention\n",
        "3. Use  trained&deployee YOLO model to mark table boundaries\n",
        "4. Extract sub Images by cutting those tables out of original images.\n",
        "5. Perform OCR on tables and extract the text matrix\n",
        "6. Send the text to openai and generate a summary of the table."
      ],
      "metadata": {
        "id": "LDzVfHpd7UVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thl8xUts5byX",
        "outputId": "7433b468-bdbe-425a-8fbb-874ac143d0cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/yoloSign\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTTxd07k7zEg",
        "outputId": "98d0fe9e-fb00-4e82-f0e5-fc172f787900"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yoloSign\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Read document (pdf) from a given location\n",
        "\n",
        "To read a document on goole colab\n",
        " that isIt is easy to upload document to google drive but To read a document that is not on Google Drive and we don't want to upload it manually each time we can use Google Colab following steps\n",
        "\n",
        "\n",
        "*   Upload Directly to google drive and note the path where the document is uploaded : go to the folder and upload the document \"/content/drive/MyDrive/yoloSign/Pdf_document/*.pdf\"\n",
        "*   If is not on Google Drive and we don't want to upload it manually each time and its availabe as a online URL document (see below)\n",
        "\n",
        "\n",
        "# 2. Split the document into pages and covert each page into png/jpg format and save them with appropriate naming convention\n",
        "\n",
        "*   For this we use package pdf2image and Poppler"
      ],
      "metadata": {
        "id": "Ozibjezw8l_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyPDF2\n",
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "\n",
        "\n",
        "!pip install pdf2image\n",
        "# Install Poppler\n",
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "i9zEtxSV8h4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "form_name =['f114a','f3115','f1120-RIC','f1120-REIT','f1120-PC','fw4','f1120','f8453']\n"
      ],
      "metadata": {
        "id": "AOGUnc8H5PBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "\n",
        "form_names = [ 'fw4', 'f3115', 'f1120ric', 'f1120pc',  'f1120', 'f8453']\n",
        "constant_path = '/content/drive/MyDrive/yoloSign/Pdf_document/'\n",
        "output_dir = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(constant_path, exist_ok=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for form_name in form_names:\n",
        "    pdf_url = f\"https://www.irs.gov/pub/irs-pdf/{form_name}.pdf\"\n",
        "    filename = f\"{form_name}.pdf\"\n",
        "    file_path = os.path.join(constant_path, filename)\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"The file {filename} already exists at {file_path}. No download needed.\")\n",
        "    else:\n",
        "        response = requests.get(pdf_url)\n",
        "        if response.status_code == 200:\n",
        "            with open(file_path, 'wb') as pdf_file:\n",
        "                pdf_file.write(response.content)\n",
        "            print(f\"PDF successfully saved to {file_path}\")\n",
        "        else:\n",
        "            print(f\"Failed to retrieve the PDF document for {form_name}.\")\n",
        "\n",
        "\n",
        "    # Convert PDF to a list of PNG images\n",
        "    images = convert_from_path(file_path)\n",
        "\n",
        "    # Save PNG images to files\n",
        "    for i, image in enumerate(images):\n",
        "        image_output_path = os.path.join(output_dir, f\"{form_name}_page_{i + 1}.png\")\n",
        "        image.save(image_output_path, \"PNG\")\n",
        "\n",
        "    print(f\"The images for {form_name} are saved in {output_dir}\")"
      ],
      "metadata": {
        "id": "GsyIe2aV8P7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#document_name = \"AutomateDocument.pdf\"\n",
        "#constant_path = \"/content/drive/MyDrive/yolov7/Table-Extraction-PDF-2/\"\n",
        "#constant_path = \"/content/drive/MyDrive/yoloSign/Pdf_document/\"\n",
        "#pdf_file = constant_path + document_name\n",
        "#outdir = filename.replace(\".pdf\", \"\")\n",
        "#output_dir =constant_path + \"Pdf_To_Images/\" + outdir\n",
        "output_dir_ = output_dir +\"/\"\n",
        "inf_dir = output_dir_ + \"detect/\"\n",
        "\n",
        "\n",
        "specialvar = outdir+\"_Employee\"\n",
        "\n",
        "# the directory from which the weights are taken for inference\n",
        "#model_dir = \"/content/drive/MyDrive/yolov8/runs/detect/train4/weights/best.pt\"\n",
        "model_dir = \"/content/drive/MyDrive/yolov8/runs/detect/yolo8_best.pt\"\n",
        "train_data =\"/content/drive/MyDrive/yolov8/Table-Extraction-PDF-2\""
      ],
      "metadata": {
        "id": "jw6UBLRd_FdT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv  /content/drive/MyDrive/yoloSign/Pdf_document/Pdf_Images /content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images"
      ],
      "metadata": {
        "id": "LdDxbQTMEp5t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpath = \"/content/drive/MyDrive/yoloSign/\"\n",
        "tpath = fpath + \"train\"\n",
        "ipath =  tpath + \"/images/\"\n",
        "lpath  = tpath + \"/labels/\"\n",
        "bpath  =  tpath + \"/box_images/\"\n",
        "testpath = fpath + \"test\"\n",
        "itestpath = testpath + \"/images/\"\n",
        "vpath = fpath + \"valid\"\n",
        "ivpath = vpath + \"/images/\"\n",
        "lvpath = vpath + \"/labels/\"\n",
        "\n",
        "os.makedirs(tpath, exist_ok=True)\n",
        "os.makedirs(ipath, exist_ok=True)\n",
        "os.makedirs(lpath, exist_ok=True)\n",
        "os.makedirs(bpath, exist_ok=True)\n",
        "os.makedirs(testpath, exist_ok=True)\n",
        "os.makedirs(itestpath, exist_ok=True)\n",
        "os.makedirs(vpath, exist_ok=True)\n",
        "os.makedirs(ivpath, exist_ok=True)\n",
        "os.makedirs(lvpath, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "J3oBJPyreTRO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annotation or Labelling Images\n",
        "\n",
        "Labeling images for any YOLO version, requires a tool that can annotate images with bounding boxes and associate each box with a class label. There are several tools available for this purpose, each with its own set of features and user interfaces. The best tool can depend on the specific needs, such as ease of use, functionality, and compatibility with YOLO formats. There are some tools for image labeling like LabelImg, Labelbox, roboflow  and so on.\n",
        "\n",
        "Roboflow has been used for the annotation of the images for YOLO, the platform typically manages the conversion of annotation coordinates to the format required by YOLO models. YOLO uses a specific bounding box format which includes:\n",
        "\n",
        "The center of the bounding box (x, y) relative to the width and height of the image.\n",
        "The width and height of the bounding box relative to the width and height of the image.\n",
        "\n",
        "These values are normalized to be between 0 and 1. Here's the format:\n",
        "\n",
        "<class_id> <x_center> <y_center> <width> <height>\n",
        "\n",
        "Each line in a YOLO annotation .txt file corresponds to a bounding box in the respective image and follows the format mentioned above.\n",
        "\n",
        "e.g.\n",
        "\n",
        "0   0.496875 0.77578125 0.9265625 0.0828125\n",
        "\n",
        "here 0 indicates the class . we can multiclass labelling also\n"
      ],
      "metadata": {
        "id": "uEfa7-gTlhCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Simulated dataset\n",
        "\n",
        "To achieve the goal of creating a generated\\simulated dataset for YOLO training, we'll need to follow a process that involves cutting out the annotated portion of the image and then pasting it onto various sections of other documents. Let's break down the steps\n",
        "\n",
        "# Cutting the Annotated Portion from the Image\n",
        "Based on the YOLO annotation line (e.g., 0 0.51 0.33 0.27 0.50), we need to extract the corresponding part of the image. The annotation gives us the center coordinates of the bounding box, along with its width and height relative to the image size.\n",
        "\n",
        "1. **Calculate Absolute Bounding Box Coordinates**:\n",
        "      * Convert the relative coordinates to absolute pixel values based on the image size.\n",
        "      * Calculate the top-left corner of the bounding box from its center coordinates.\n",
        "2. **Crop the Image**\n",
        "      * Use these coordinates to crop the region from the image."
      ],
      "metadata": {
        "id": "T7rXW7odN4da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image,ImageDraw\n",
        "\n",
        "def crop_annotation(image_path, annotation):\n",
        "    # Load the image\n",
        "    image = Image.open(image_path)\n",
        "    img_width, img_height = image.size\n",
        "\n",
        "    # Parse the annotation\n",
        "    _, x_center, y_center, width, height = map(float, annotation.split())\n",
        "\n",
        "    # Convert YOLO format to pixel values\n",
        "    box_width = width * img_width\n",
        "    box_height = height * img_height\n",
        "    x_center *= img_width\n",
        "    y_center *= img_height\n",
        "\n",
        "    # Calculate top-left corner of the bounding box\n",
        "    x1 = int(x_center - box_width / 2)\n",
        "    y1 = int(y_center - box_height / 2)\n",
        "\n",
        "    # Crop the image\n",
        "    cropped_image = image.crop((x1, y1, x1 + int(box_width), y1 + int(box_height)))\n",
        "\n",
        "    return cropped_image"
      ],
      "metadata": {
        "id": "TWE5WZY8Nn4C"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_image = \"0 0.506875 0.77578125 0.9265625 0.0898125\"\n",
        "file_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4_page_1.png'\n",
        "cropped_image = crop_annotation(file_path,label_image)\n",
        "cropped_image.save(bpath+'/cropped_image_'+ specialvar +'.png')\n"
      ],
      "metadata": {
        "id": "hBmTSrVwTByf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Generated Dataset\n",
        "Paste this cropped section onto various parts of other documents. Here lets start with one document\n",
        "\n",
        "**Prepare Target Documents:**\n",
        "\n",
        "  * Have a set of target documents (images) where we can paste the cropped section.\n",
        "\n",
        "**Random Placement of Cropped Section:**\n",
        "\n",
        "  * Choose random positions on these target documents to paste the cropped section.\n",
        "\n",
        "  * Ensure the pasted section fits within the boundaries of the target documents.\n",
        "\n",
        "  \n",
        "**Save the Modified Documents:**\n",
        "\n",
        "  * Save each modified document as a new image file.\n"
      ],
      "metadata": {
        "id": "D6CPhj7JUK7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def paste_on_background(background_path, cropped_image, output_path,output_box_path, position):\n",
        "    background = Image.open(background_path)\n",
        "    background_width, background_height = background.size\n",
        "\n",
        "    # Create a copy of the background for drawing the bounding box\n",
        "    background_with_box = background.copy()\n",
        "\n",
        "\n",
        "    # Paste the cropped image onto the background at the specified position\n",
        "    background.paste(cropped_image, position, cropped_image if cropped_image.mode == 'RGBA' else None)\n",
        "    background_with_box.paste(cropped_image, position, cropped_image if cropped_image.mode == 'RGBA' else None)\n",
        "\n",
        "\n",
        "    # Draw bounding box for visualization (optional)\n",
        "    draw = ImageDraw.Draw(background_with_box)\n",
        "    x1, y1 = position\n",
        "    x2, y2 = x1 + cropped_image.width, y1 + cropped_image.height\n",
        "    draw.rectangle([x1, y1, x2, y2], outline=\"red\")\n",
        "\n",
        "    # Save the result\n",
        "    background.save(output_image_path)\n",
        "    background_with_box.save(output_box_path.replace('.png', '_bbox.png'))\n",
        "    print(f\"Saved images to {output_image_path} and {output_box_path.replace('.png', '_bbox.png')}\")\n",
        "\n",
        "\n",
        "    # Calculate YOLO format coordinates\n",
        "    bbox_x_center = (x1 + x2) / 2 / background_width\n",
        "    bbox_y_center = (y1 + y2) / 2 / background_height\n",
        "    bbox_width = cropped_image.width / background_width\n",
        "    bbox_height = cropped_image.height / background_height\n",
        "\n",
        "    yolo_format = (bbox_x_center, bbox_y_center, bbox_width, bbox_height)\n",
        "    return yolo_format"
      ],
      "metadata": {
        "id": "p2iW08XiUtFj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/'\n",
        "output_dir_ = output_dir +\"/\"\n",
        "inf_dir = output_dir_ + \"detect/\"\n",
        "os.makedirs(output_dir_, exist_ok=True)\n",
        "os.makedirs(inf_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "1irvEzbhVO07"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Train dataset\n",
        "\n",
        "1.  Took 3rd page of all the document and pasted the cropped image of the first page of sign image of fw4 placed at randomly generated various positon\n",
        "\n"
      ],
      "metadata": {
        "id": "6C_aMcF1Q3Hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_image = \"0 0.506875 0.77578125 0.9265625 0.0898125\"\n",
        "file_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4_page_1.png'\n",
        "cropped_image = crop_annotation(file_path,label_image)\n",
        "cropped_image.save(bpath+'/cropped_image_'+ specialvar +'.png')\n",
        "\n",
        "specialvar = form_names[0]\n",
        "exclusion_pattern = specialvar + \"_page_1.png\"\n",
        "document_paths = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('_page_3.png') and  f != exclusion_pattern ]\n",
        "for doc_path in document_paths:\n",
        "  for i in range(0, 20):\n",
        "    pos_y = random.randint(40, 2000)\n",
        "    position = (100, pos_y)\n",
        "    output_image_path = os.path.join(ipath, os.path.basename(doc_path).replace('.png','') + '_'+specialvar + '_' +str(i) +'.png' )\n",
        "    output_box_path = os.path.join(bpath, os.path.basename(doc_path).replace('.png','') + '_'+specialvar + '_' +str(i) +'_bbox.png' )\n",
        "\n",
        "    yolo_coordinates = paste_on_background(doc_path, cropped_image, output_image_path, output_box_path, position)\n",
        "\n",
        "    with open(os.path.join(lpath, os.path.basename(doc_path).replace('.png','') + '_'+specialvar + '_' +str(i) + '.txt'), 'w') as file:\n",
        "        file.write(f\"0 {yolo_coordinates[0]} {yolo_coordinates[1]} {yolo_coordinates[2]} {yolo_coordinates[3]}\")\n"
      ],
      "metadata": {
        "id": "h3nYfzqQO-pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Copy all other images (not the 1st) as they dnt have sign document with a empty label file for training dataset."
      ],
      "metadata": {
        "id": "6o7zR3n0TV2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_paths = [os.path.join(output_dir, f) for f in os.listdir(output_dir) ]\n",
        "from shutil import copyfile\n",
        "for doc_path in document_paths:\n",
        "    # Extract the base file name without page number and extension\n",
        "    base_file_name = os.path.basename(doc_path).rsplit('_', 2)[0]\n",
        "\n",
        "    page_num = 2  # Starting from the second page\n",
        "    while True:\n",
        "        # Construct the new page path\n",
        "        page_path = os.path.join(os.path.dirname(doc_path), f\"{base_file_name}_page_{page_num}.png\")\n",
        "        if not os.path.exists(page_path):\n",
        "            break  # Stop if the page does not exist\n",
        "\n",
        "        # Copy image to training images directory\n",
        "        dest_image_path = os.path.join(ipath, f\"{base_file_name}_page_{page_num}.png\")\n",
        "        copyfile(page_path, dest_image_path)\n",
        "\n",
        "        # Create an empty file in labels directory\n",
        "        with open(os.path.join(lpath, f\"{base_file_name}_page_{page_num}.txt\"), 'w') as file:\n",
        "            pass  # Empty file\n",
        "\n",
        "        page_num += 1"
      ],
      "metadata": {
        "id": "-Op5QCkhxWJ8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing data for Validation dataset\n",
        "\n",
        "Coping the 20% of generated train data to validation dataset"
      ],
      "metadata": {
        "id": "XM-nGtD_Y6YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "# Get a list of filenames (without extensions) in the training images directory\n",
        "train_filenames = [os.path.splitext(f)[0] for f in os.listdir(ipath) if f.endswith('.png')]\n",
        "\n",
        "# Decide how many images you want to move to validation (e.g., 20% of the training set)\n",
        "num_valid = int(len(train_filenames) * 0.2)\n",
        "\n",
        "# Randomly select images for validation\n",
        "valid_filenames = random.sample(train_filenames, num_valid)\n",
        "\n",
        "# Copy selected images and their corresponding label files to validation directories\n",
        "for filename in valid_filenames:\n",
        "    # Copy image\n",
        "    src_image_path = os.path.join(ipath, filename + '.png')\n",
        "    dst_image_path = os.path.join(ivpath, filename + '.png')\n",
        "    shutil.copyfile(src_image_path, dst_image_path)\n",
        "\n",
        "    # Copy label file\n",
        "    src_label_path = os.path.join(lpath, filename + '.txt')\n",
        "    dst_label_path = os.path.join(lvpath, filename + '.txt')\n",
        "    shutil.copyfile(src_label_path, dst_label_path)\n",
        "\n",
        "print(f\"Copied {num_valid} images and their labels to the validation directories.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SqAF7U0Y5vo",
        "outputId": "b22a61a9-6513-450d-b1e6-a9b9a8451964"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 27 images and their labels to the validation directories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing data for Test dataset.\n",
        "\n",
        "Just coping all the first page of all the form for the test data"
      ],
      "metadata": {
        "id": "EBKaav__OkCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "\n",
        "\n",
        "# Copy all files ending with 'page_1.png'\n",
        "for filename in os.listdir(output_dir):\n",
        "    if filename.endswith('fw4_page_1.png'):\n",
        "        source_file_path = os.path.join(output_dir, filename)\n",
        "        destination_file_path = os.path.join(itestpath, filename)\n",
        "        copyfile(source_file_path, destination_file_path)\n",
        "        print(f\"Copied {filename} to {itestpath}\")"
      ],
      "metadata": {
        "id": "P9580kMGOupi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training YOLOv8 on a Custom Dataset (identify Sign Boxes)\n",
        "\n",
        "This notebook is based on the ultralytics package and performs training on own custom objects and here i am using a document set and trying to tag sign boxesfrom the scanned/screenshot images\n",
        "\n",
        "\n",
        "### **Steps that are followed**\n",
        "\n",
        "To train the yolov8 follow steps:\n",
        "\n",
        "* Install YOLOv8 and all its dependencies\n",
        "* Load custom dataset here i took document-parts dataset\n",
        "* Run YOLOv8 training\n",
        "* Evaluate YOLOv8 performance\n",
        "* Run YOLOv8 inference on test images"
      ],
      "metadata": {
        "id": "kiKBg-d4VRBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OyX7vcvSUbRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recommended way of installing through pip\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "fUiHm2sXUazv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train YOLOv8 on a custom dataset"
      ],
      "metadata": {
        "id": "KsSXISvbWAhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir_train = \"/content/drive/MyDrive/yolov8/runs/detect/yolo8_best.pt\"\n",
        "train_data = \"/content/drive/MyDrive/yoloSign/\"\n"
      ],
      "metadata": {
        "id": "IV2tso5OWhXe"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect \\\n",
        "mode=train \\\n",
        "model={model_dir_train} \\\n",
        "data={train_data}/data.yaml \\\n",
        "epochs=15 \\\n",
        "imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIo-fTvqV-ro",
        "outputId": "4b345d03-0e07-434c-bdf4-c3da12c046d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.227 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/yolov8/runs/detect/yolo8_best.pt, data=/content/drive/MyDrive/yoloSign//data.yaml, epochs=15, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "2023-12-14 19:03:04.921264: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-14 19:03:04.921318: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-14 19:03:04.922656: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=2 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "WARNING ‚ö†Ô∏è NMS time limit 0.550s exceeded\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/yoloSign/train/labels.cache... 138 images, 27 backgrounds, 0 corrupt: 100% 138/138 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/yoloSign/valid/labels.cache... 27 images, 7 backgrounds, 0 corrupt: 100% 28/28 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/15      2.39G      1.742      3.429      1.413         13        640: 100% 9/9 [00:07<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.65s/it]\n",
            "                   all         28         21      0.513      0.552      0.751      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/15      2.26G      1.101      2.146      1.082         17        640: 100% 9/9 [00:02<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.72it/s]\n",
            "                   all         28         21          1      0.381      0.976      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/15      2.25G     0.9261      1.707      1.023         15        640: 100% 9/9 [00:03<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.86it/s]\n",
            "                   all         28         21      0.949      0.894      0.925      0.745\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/15      2.26G      0.784      1.494     0.9858         18        640: 100% 9/9 [00:04<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.41it/s]\n",
            "                   all         28         21      0.951          1       0.95      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/15      2.25G     0.7491      1.362     0.9418         14        640: 100% 9/9 [00:02<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.16it/s]\n",
            "                   all         28         21      0.952          1      0.952      0.701\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/15      2.27G     0.6283      1.826     0.9145          7        640: 100% 9/9 [00:10<00:00,  1.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.62it/s]\n",
            "                   all         28         21      0.952      0.943      0.964      0.818\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/15      2.27G     0.6233      1.655     0.9188         10        640: 100% 9/9 [00:03<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.53it/s]\n",
            "                   all         28         21      0.927      0.905      0.975      0.756\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/15      2.27G     0.6182      1.625     0.8866          8        640: 100% 9/9 [00:02<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.79it/s]\n",
            "                   all         28         21      0.954      0.998      0.985      0.879\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/15      2.27G     0.6192      1.559     0.8894          7        640: 100% 9/9 [00:03<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.25it/s]\n",
            "                   all         28         21      0.954          1      0.986      0.855\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/15      2.27G     0.5762      1.438     0.8908          8        640: 100% 9/9 [00:02<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.00it/s]\n",
            "                   all         28         21      0.949          1      0.989      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/15      2.27G     0.5901      1.345     0.8414          8        640: 100% 9/9 [00:02<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.63it/s]\n",
            "                   all         28         21      0.949          1      0.986      0.904\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/15      2.27G     0.5037       1.29     0.8504          9        640: 100% 9/9 [00:03<00:00,  2.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.75it/s]\n",
            "                   all         28         21      0.952          1      0.986      0.917\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/15      2.26G     0.5416      1.322     0.8755          5        640: 100% 9/9 [00:03<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.41it/s]\n",
            "                   all         28         21      0.952          1      0.986      0.936\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/15      2.25G     0.4271      1.168     0.8294          7        640: 100% 9/9 [00:02<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.42it/s]\n",
            "                   all         28         21      0.952          1       0.98       0.93\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/15      2.27G     0.4296       1.17     0.8203          8        640: 100% 9/9 [00:02<00:00,  4.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.29it/s]\n",
            "                   all         28         21      0.952          1      0.978      0.923\n",
            "\n",
            "15 epochs completed in 0.025 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.227 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.33it/s]\n",
            "                   all         28         21      0.952          1      0.986      0.929\n",
            "Speed: 0.2ms preprocess, 2.8ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate with a new model\n",
        "\n",
        "When the *training* is over, we can validate the new model on images it has not seen before. Therefore, when creating a dataset, we divide it into three parts, and one of them that we will use now as a test dataset."
      ],
      "metadata": {
        "id": "pWpoCmUfckL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"runs/detect/train/weights/best.pt\"\n",
        "testpath = \"/content/drive/MyDrive/yoloSign/test/images/\""
      ],
      "metadata": {
        "id": "eJCXz3QVfSN7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect \\\n",
        "mode=val \\\n",
        "model= {model_dir} \\\n",
        "data= {train_data}/data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlWYESGwcp8c",
        "outputId": "37c270a8-42c0-417a-e611-ff2c3c0ea11e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.227 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/yoloSign/valid/labels.cache... 27 images, 7 backgrounds, 0 corrupt: 100% 28/28 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:03<00:00,  1.67s/it]\n",
            "                   all         28         21      0.952          1      0.986      0.944\n",
            "Speed: 3.2ms preprocess, 17.6ms inference, 0.0ms loss, 40.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on a new data"
      ],
      "metadata": {
        "id": "fCEcg2r3dCMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect \\\n",
        "mode=predict \\\n",
        "model={model_dir} \\\n",
        "conf=0.25 \\\n",
        "source={testpath} \\\n",
        "name={inf_dir} \\\n",
        "save_txt= True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJGBsaS8dA9E",
        "outputId": "b6e89613-06ba-4084-8f19-20a66c8b6c26"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.227 üöÄ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/yoloSign/test/images/fw4_page_1.png: 640x512 1 sign, 83.0ms\n",
            "Speed: 5.6ms preprocess, 83.0ms inference, 534.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/detect\u001b[0m\n",
            "1 label saved to /content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/detect/labels\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "a35wUxAyeDPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "document_paths = [os.path.join(output_dir, f) for f in os.listdir(output_dir) ]\n",
        "print(document_paths)\n",
        "from shutil import copyfile\n",
        "for doc_path in document_paths:\n",
        "    # Extract the base file name without page number and extension\n",
        "    base_file_name = os.path.basename(doc_path).rsplit('_', 2)[0]\n",
        "\n",
        "    page_num = 2  # Starting from the second page\n",
        "    while True:\n",
        "        # Construct the new page path\n",
        "        page_path = os.path.join(os.path.dirname(doc_path), f\"{base_file_name}_page_{page_num}.png\")\n",
        "        if not os.path.exists(page_path):\n",
        "            break  # Stop if the page does not exist\n",
        "\n",
        "        # Copy image to training images directory\n",
        "        dest_image_path = os.path.join(ipath, f\"{base_file_name}_page_{page_num}.png\")\n",
        "        copyfile(page_path, dest_image_path)\n",
        "\n",
        "        # Create an empty file in labels directory\n",
        "        with open(os.path.join(lpath, f\"{base_file_name}_page_{page_num}.txt\"), 'w') as file:\n",
        "            pass  # Empty file\n",
        "\n",
        "        page_num += 1"
      ],
      "metadata": {
        "id": "VDRjJcFVOigI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specialvar = form_names[0]\n",
        "form_names = [ 'fw4', 'f3115', 'f1120ric', 'f1120pc',  'f1120', 'f8453']\n",
        "exclusion_pattern = specialvar + \"_page_1.png\"\n",
        "document_paths = [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith('_page_1.png') and  f != exclusion_pattern ]\n",
        "print(document_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP7iw1JYUu7h",
        "outputId": "5cc87936-f684-41a2-df5c-6b9a39e3aaa7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/f3115_page_1.png', '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/f1120ric_page_1.png', '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/f1120pc_page_1.png', '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/f1120_page_1.png', '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/f8453_page_1.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "# Specify the PDF file path\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Convert PDF to a list of PNG images\n",
        "images = convert_from_path(file_path)\n",
        "\n",
        "# Save PNG images to files\n",
        "for i, image in enumerate(images):\n",
        "    image.save(os.path.join(output_dir, f\"output_page_{i + 1}.png\"), \"PNG\")\n",
        "print(\"The images are saved in \", output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En9HilFrGN01",
        "outputId": "5a475364-090b-4d17-fd93-dc9a6acde43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The images are saved in  /content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_image = \"0 0.506875 0.77578125 0.9265625 0.0898125\"\n",
        "file_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_1.png'\n",
        "cropped_image = crop_annotation(file_path,label_image)\n",
        "cropped_image.save(bpath+'/cropped_image_'+ specialvar +'.png')\n",
        "\n",
        "\n",
        "\n",
        "background_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_3.png'\n",
        "for i in range(0, 100):\n",
        "    pos_y = random.randint(40, 2000)\n",
        "    position = (100, pos_y)\n",
        "    output_image_path = f'{ipath}{specialvar}_{i}.png'\n",
        "    output_boximage_path = f'{bpath}{specialvar}_{i}.png'\n",
        "    yolo_coordinates = paste_on_background(background_path, cropped_image, output_image_path,output_boximage_path, position)\n",
        "\n",
        "    with open(f'{lpath}{specialvar}_{i}.txt', 'w') as file:\n",
        "        file.write(f\"0 {yolo_coordinates[0]} {yolo_coordinates[1]} {yolo_coordinates[2]} {yolo_coordinates[3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0nYS4rLVA1l",
        "outputId": "dd770661-13cc-46da-b8fa-bb0cf249d613"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_0.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_0_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_1.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_1_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_2.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_2_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_3.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_3_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_4.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_4_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_5.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_5_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_6.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_6_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_7.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_7_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_8.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_8_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_9.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_9_bbox.png\n",
            "Saved images to /content/drive/MyDrive/yoloSign/train/images/fw4_Employee_10.png and /content/drive/MyDrive/yoloSign/train/box_images/fw4_Employee_10_bbox.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "constant_path = \"/content/drive/MyDrive/yoloSign/Pdf_document/\"\n",
        "\n",
        "import os\n",
        "import requests\n",
        "# URL of the PDF document\n",
        "pdf_url = \"https://www.irs.gov/pub/irs-pdf/fw4.pdf\"\n",
        "# Extracting the filename from the URL\n",
        "filename = pdf_url.split('/')[-1]\n",
        "file_path = os.path.join(constant_path, filename)\n",
        "# Check if the file already exists\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"The file {filename} already exists at {file_path}. No download needed.\")\n",
        "else:\n",
        "    # Fetch the PDF content from the URL\n",
        "    response = requests.get(pdf_url)\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        # Save the PDF to the specified directory\n",
        "        with open(file_path, 'wb') as pdf_file:\n",
        "            pdf_file.write(response.content)\n",
        "        print(f\"PDF successfully saved to {file_path}\")\n",
        "    else:\n",
        "        print(\"Failed to retrieve the PDF document.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55KLmKTrEkiV",
        "outputId": "a102d588-d01b-45bf-81fb-702c2ef6c6c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file fw4.pdf already exists at /content/drive/MyDrive/yoloSign/Pdf_document/fw4.pdf. No download needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "background_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_1.png'\n",
        "overlay_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_3.png'\n",
        "output_path = 'image_with_overlay.png'\n",
        "background = Image.open(background_path)\n",
        "overlay = Image.open(overlay_path)\n",
        "# Print out their modes\n",
        "print(f\"Background mode: {background.mode}\")\n",
        "print(f\"Overlay mode: {overlay.mode}\")\n",
        "\n",
        "# Convert overlay to 'RGBA' if it's not already\n",
        "if overlay.mode != 'RGBA':\n",
        "    overlay = overlay.convert('RGBA')\n",
        "\n",
        "\n",
        "# Calculate the new height to maintain the aspect ratio\n",
        "aspect_ratio = overlay.width / overlay.height\n",
        "new_height = int((overlay.width*0.95) / aspect_ratio)\n",
        "\n",
        "# Resize the overlay image to match the width of the background\n",
        "overlay = overlay.resize((int(overlay.width*0.95), new_height))\n",
        "\n",
        "position = (100, 1625)\n",
        "print(f\"Background size: {background.size}\")\n",
        "print(f\"Resized overlay size: {overlay.size}\")\n",
        "print(f\"Position to paste: {position}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "(x,y) = position\n",
        "\n",
        "box = (x,y,x+overlay.width, y+overlay.height)\n",
        "cropped_region = background.crop(box)\n",
        "pos_o_x = 100\n",
        "pos_o_y = 1625\n",
        "background.paste(cropped_region,(pos_o_x,pos_o_y))\n",
        "\n",
        "    # Paste the overlay image onto the background at the specified position\n",
        "background.paste(overlay, position, overlay)\n",
        "\n",
        "#background.paste(overlay, position,overlay)\n",
        "\n",
        "# Save the combined image\n",
        "output_path = 'image_with_overlay.png'\n",
        "background.save(output_path)\n",
        "print(f\"Image saved to {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLpLU08uM9J3",
        "outputId": "e0b9f1b5-3b5b-40b1-d35c-2c78ca2ebab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Background mode: RGB\n",
            "Overlay mode: RGB\n",
            "Background size: (1700, 2200)\n",
            "Resized overlay size: (1615, 2090)\n",
            "Position to paste: (100, 1625)\n",
            "Image saved to image_with_overlay.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Variable Names\n",
        "background_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_1.png'\n",
        "overlay_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_1.png'\n",
        "output_path = 'image_with_overlay.png'\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "def get_image_dimensions(image_path):\n",
        "    # Open the subimage using PIL/Pillow\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Get the width and height of the subimage\n",
        "    width, height = image.size\n",
        "\n",
        "    return width, height\n",
        "def overlay_subimage(background_path, overlay_path, output_path, position):\n",
        "    # Open the background and overlay images\n",
        "    background = Image.open(background_path)\n",
        "    overlay = Image.open(overlay_path)\n",
        "\n",
        "    # Resize the overlay image to make sure it fits within the background\n",
        "    max_width = background.width - position[0]  # Maximum width the overlay can have\n",
        "    aspect_ratio = overlay.width / overlay.height\n",
        "    new_height = int(min(overlay.height, (max_width / aspect_ratio)))\n",
        "    new_width = int(min(overlay.width, max_width))\n",
        "    overlay_resized = overlay.resize((new_width, new_height))\n",
        "\n",
        "    # Calculate the box for cropping (ensure it's within the background boundaries)\n",
        "    x, y = position\n",
        "    box_width = min(overlay_resized.width, background.width - x)\n",
        "    box_height = min(overlay_resized.height, background.height - y)\n",
        "    box = (x, y, x + box_width, y + box_height)\n",
        "\n",
        "    # Paste the resized overlay image onto the background at the specified position\n",
        "    background.paste(overlay_resized, position, overlay_resized if overlay_resized.mode == 'RGBA' else None)\n",
        "\n",
        "    # Save the result\n",
        "    background.save(output_path)\n",
        "    print(f\"Saved image to {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate bounding box parameters\n",
        "    (x,y) = position\n",
        "    height, width = background.height, background.width\n",
        "    center_x = (x + overlay.width / 2) / width\n",
        "    center_y = (y + overlay.height / 2) / height\n",
        "    normalized_width = overlay.width / width\n",
        "    normalized_height = overlay.height / height\n",
        "\n",
        "    # Express bounding box in YOLO format\n",
        "    yolo_format = (center_x, center_y, normalized_width, normalized_height)\n",
        "\n",
        "    # Save the result\n",
        "\n",
        "    return yolo_format\n",
        "\n",
        "\n",
        "def draw_bounding_box(img_path,ybox):\n",
        "    img = cv2.imread(img_path)\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    center_x, center_y, normalized_width, normalized_height = ybox\n",
        "\n",
        "    # Draw bounding box on the image for visualization\n",
        "    box_x = int((center_x - normalized_width / 2) * width)\n",
        "    box_y = int((center_y - normalized_height / 2) * height)\n",
        "    cv2.rectangle(img, (box_x, box_y), (box_x + int(normalized_width * width), box_y + int(normalized_height * height)), (0, 255, 0), 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "subimage_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_1.png'\n",
        "bkg_width, bkg_height = get_image_dimensions(background_path)\n",
        "\n",
        "print(\"Subimage dimensions:\", bkg_width, \"x\", bkg_height)\n",
        "\n",
        "import random\n",
        "\n",
        "pos_o_x = 100\n",
        "pos_o_y = 1625\n",
        "\n",
        "for i in range(0,11):\n",
        "    pos_y = random.randint(40,2000)\n",
        "    print(pos_y)\n",
        "    position = (100, pos_y)  # Example coordinates\n",
        "    ybox = overlay_subimage(background_path, overlay_path, output_path, position)\n",
        "    # Display the image with bounding box\n",
        "    img = draw_bounding_box(output_path, ybox)\n",
        "    cv2.imwrite('output_image_?i?.jpg'.replace('?i?',str(i)), img)\n",
        "    print(i,pos_y)\n",
        "\n",
        "#cv2.imshow('Image with bounding box', img)\n",
        "#cv2.waitKey(0)\n",
        "#cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpJRdZWiJB_a",
        "outputId": "05e53cff-4556-4064-9c43-0bb994893c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subimage dimensions: 1700 x 2200\n",
            "1123\n",
            "100 1123 1715 3213\n",
            "0 1123\n",
            "1817\n",
            "100 1817 1715 3907\n",
            "1 1817\n",
            "746\n",
            "100 746 1715 2836\n",
            "2 746\n",
            "659\n",
            "100 659 1715 2749\n",
            "3 659\n",
            "1550\n",
            "100 1550 1715 3640\n",
            "4 1550\n",
            "1129\n",
            "100 1129 1715 3219\n",
            "5 1129\n",
            "1608\n",
            "100 1608 1715 3698\n",
            "6 1608\n",
            "1184\n",
            "100 1184 1715 3274\n",
            "7 1184\n",
            "1244\n",
            "100 1244 1715 3334\n",
            "8 1244\n",
            "765\n",
            "100 765 1715 2855\n",
            "9 765\n",
            "1544\n",
            "100 1544 1715 3634\n",
            "10 1544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "background_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_1.png'\n",
        "overlay_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_1.png'\n",
        "output_path = 'image_with_overlay.png'\n",
        "\n",
        "# Load the background and overlay images to get their dimensions\n",
        "background = Image.open(background_path)\n",
        "overlay = Image.open(overlay_path)\n",
        "bkg_width, bkg_height = background.size\n",
        "\n",
        "# Resize overlay and get new dimensions\n",
        "aspect_ratio = overlay.width / overlay.height\n",
        "max_width = bkg_width - 100  # Assuming '100' is the fixed x-coordinate for the overlay\n",
        "new_height = int((overlay.width * 0.95) / aspect_ratio)\n",
        "new_width = int(min(overlay.width * 0.95, max_width))\n",
        "\n",
        "# Adjust new_height if it exceeds background boundaries\n",
        "if new_height > (bkg_height - 100):  # Assuming '100' is the minimum y-coordinate\n",
        "    new_height = bkg_height - 100\n",
        "    new_width = int(new_height * aspect_ratio)\n",
        "\n",
        "\n",
        "def overlay_subimage(background_path, overlay_path, output_path, position, new_width, new_height):\n",
        "    # Open the background and overlay images\n",
        "    background = Image.open(background_path)\n",
        "    overlay = Image.open(overlay_path)\n",
        "\n",
        "    # Resize the overlay\n",
        "    overlay_resized = overlay.resize((new_width, new_height))\n",
        "\n",
        "    # Paste the resized overlay image onto the background\n",
        "    background.paste(overlay_resized, position)\n",
        "\n",
        "\n",
        "    # Calculate bounding box parameters\n",
        "    (x,y) = position\n",
        "    height, width = background.height, background.width\n",
        "    center_x = (x + overlay.width / 2) / width\n",
        "    center_y = (y + overlay.height / 2) / height\n",
        "    normalized_width = overlay.width / width\n",
        "    normalized_height = overlay.height / height\n",
        "\n",
        "    # Express bounding box in YOLO format\n",
        "    yolo_format = (center_x, center_y, normalized_width, normalized_height)\n",
        "\n",
        "    # Save the result\n",
        "    background.save(output_path)\n",
        "    return yolo_format\n",
        "\n",
        "\n",
        "def draw_bounding_box(img_path,ybox):\n",
        "    img = cv2.imread(img_path)\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    center_x, center_y, normalized_width, normalized_height = ybox\n",
        "\n",
        "    # Draw bounding box on the image for visualization\n",
        "    box_x = int((center_x - normalized_width / 2) * width)\n",
        "    box_y = int((center_y - normalized_height / 2) * height)\n",
        "    cv2.rectangle(img, (box_x, box_y), (box_x + int(normalized_width * width), box_y + int(normalized_height * height)), (0, 255, 0), 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "import random\n",
        "\n",
        "for i in range(0, 11):\n",
        "    # Ensure the overlay is always within the background boundaries\n",
        "    pos_y = random.randint(40, bkg_height - new_height)\n",
        "    position = (100, pos_y)  # Example coordinates\n",
        "\n",
        "    # Call the function to overlay the image\n",
        "    ybox = overlay_subimage(background_path, overlay_path, f'output_image_{i}.png', position,new_width, new_height)\n",
        "\n",
        "    # Display the image with bounding box\n",
        "    img = draw_bounding_box(output_path, ybox)\n",
        "    cv2.imwrite('output_image_?i?.jpg'.replace('?i?',str(i)), img)\n",
        "    print(i,pos_y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzUwpDI1R1rs",
        "outputId": "7ae5cf50-0cfa-43a6-a58c-e1b1aac59d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 43\n",
            "1 73\n",
            "2 70\n",
            "3 108\n",
            "4 43\n",
            "5 82\n",
            "6 94\n",
            "7 40\n",
            "8 50\n",
            "9 67\n",
            "10 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VACSMhMoNPvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variable Names\n",
        "background_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_1.png'\n",
        "overlay_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_3.png'\n",
        "output_path = 'image_with_overlay.png'\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "def get_image_dimensions(image_path):\n",
        "    # Open the subimage using PIL/Pillow\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Get the width and height of the subimage\n",
        "    width, height = image.size\n",
        "\n",
        "    return width, height\n",
        "def overlay_subimage(background_path, overlay_path, output_path, position):\n",
        "    # Open the background and overlay images\n",
        "    background = Image.open(background_path)\n",
        "    overlay = Image.open(overlay_path)\n",
        "\n",
        "    # Resize the overlay image if necessary\n",
        "    aspect_ratio = overlay.width / overlay.height\n",
        "    new_height = int((overlay.width * 0.95) / aspect_ratio)\n",
        "    overlay_resized = overlay.resize((int(overlay.width * 0.95), new_height))\n",
        "\n",
        "    # Paste the resized overlay image onto the background at the specified position\n",
        "    background.paste(overlay_resized, position, overlay_resized if overlay_resized.mode == 'RGBA' else None)\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate bounding box parameters\n",
        "    (x,y) = position\n",
        "    height, width = background.height, background.width\n",
        "    center_x = (x + overlay.width / 2) / width\n",
        "    center_y = (y + overlay.height / 2) / height\n",
        "    normalized_width = overlay.width / width\n",
        "    normalized_height = overlay.height / height\n",
        "\n",
        "    # Express bounding box in YOLO format\n",
        "    yolo_format = (center_x, center_y, normalized_width, normalized_height)\n",
        "\n",
        "    # Save the result\n",
        "    background.save(output_path)\n",
        "    return yolo_format\n",
        "\n",
        "\n",
        "def draw_bounding_box(img_path,ybox):\n",
        "    img = cv2.imread(img_path)\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    center_x, center_y, normalized_width, normalized_height = ybox\n",
        "\n",
        "    # Draw bounding box on the image for visualization\n",
        "    box_x = int((center_x - normalized_width / 2) * width)\n",
        "    box_y = int((center_y - normalized_height / 2) * height)\n",
        "    cv2.rectangle(img, (box_x, box_y), (box_x + int(normalized_width * width), box_y + int(normalized_height * height)), (0, 255, 0), 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "subimage_path = '/content/drive/MyDrive/yoloSign/Pdf_document/Pdf_To_Images/fw4/output_page_1.png'\n",
        "bkg_width, bkg_height = get_image_dimensions(background_path)\n",
        "\n",
        "print(\"Subimage dimensions:\", bkg_width, \"x\", bkg_height)\n",
        "\n",
        "import random\n",
        "\n",
        "pos_o_x = 100\n",
        "pos_o_y = 1625\n",
        "\n",
        "for i in range(0,11):\n",
        "    pos_y = random.randint(40,2000)\n",
        "    print(pos_y)\n",
        "    position = (100, pos_y)  # Example coordinates\n",
        "    ybox = overlay_subimage(background_path, overlay_path, output_path, position)\n",
        "    # Display the image with bounding box\n",
        "    img = draw_bounding_box(output_path, ybox)\n",
        "    cv2.imwrite('output_image_?i?.jpg'.replace('?i?',str(i)), img)\n",
        "    print(i,pos_y)\n",
        "\n",
        "#cv2.imshow('Image with bounding box', img)\n",
        "#cv2.waitKey(0)\n",
        "#cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f137d3-92a4-41b4-c471-570df870478a",
        "id": "1yNxqJJaNQMr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subimage dimensions: 1700 x 2200\n",
            "1476\n",
            "0 1476\n",
            "1628\n",
            "1 1628\n",
            "1908\n",
            "2 1908\n",
            "326\n",
            "3 326\n",
            "674\n",
            "4 674\n",
            "892\n",
            "5 892\n",
            "1359\n",
            "6 1359\n",
            "1686\n",
            "7 1686\n",
            "1686\n",
            "8 1686\n",
            "1443\n",
            "9 1443\n",
            "469\n",
            "10 469\n"
          ]
        }
      ]
    }
  ]
}