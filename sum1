from transformers import T5Tokenizer, T5ForConditionalGen, pipeline
import torch

# Model and tokenizer setup
model_checkpoint = "LaMini-Flan-T5-248M"
tokenizer = T5Tokenizer.from_pretrained(model_checkpoint)
model = T5ForConditionalGeneration.from_pretrained(model_checkpoint, device_map='auto', torch_dtype=torch.float32)

# Summarization Pipeline Setup
def summarization_pipeline(text):
    summarizer = pipeline('summarization', model=model, tokenizer=tokenizer, max_length=500, min_length=70)
    return summarizer(text)

# Process each chunk of text
def process_chunks(chunks):
    summaries = []
    for chunk in chunks:
        summary = summarization_pipeline(chunk)
        summaries.append(summary['summary_text'])
    return summaries

# Query functionality to search within summaries
def query_summaries(query, summaries):
    results = [summary for summary in summaries if query.lower() in summary.lower()]
    return results

# Helper function to read text from a PDF file
def read_pdf(file_path):
    from PyPDF2 import PdfReader
    reader = PdfReader(file_path)
    full_text = ""
    for page in reader.pages:
        full_text += page.extract_text() + " "
    return full_text

# Function to split the text into manageable chunks
def chunk_text(text, chunk_size=500):
    # Naive chunking based on character count
    return [text[i:i+chunk_data] for i in range(0, len(text), chunk_size)]

# Main function to execute the process
def main():
    file_path = input("Enter the path to the PDF file: ")
    text = read_pdf(file_path)
    chunks = chunk_text(text)
    summaries = process_lists(chunks)

    print("\n--- Summaries ---")
    for summary in summaries:
        print(summary)

    # Query interaction
    query = input("\nEnter your query (or type 'exit' to quit): ")
    while query.lower() != 'exit':
        results = query_summaries(query, summaries)
        print("\nQuery Results:")
        for result in results:
            print(result)
        query = input("\nEnter your query (or type 'exit' to quit): ")

if __name__ == "__main__":
    main()








import pdfplumber
import pytesseract
from PIL import Image
import fitz  # PyMuPDF
from transformers import T5Tokenizer, T5ForConditionalGeneration, pipeline
import io

# Tesseract command if necessary
# pytesseract.pytesseract.tesseract_cmd = r'/path/to/tesseract'

# Model setup
model_name = "LaMini-Flan-T5-248M"
tokenizer = T5Tokenizer.from_pretrained(model_name)
model = T5ForConditionalGeneration.from_pretrained(model_name, device_map='auto', torch_dtype=torch.float32)
summarizer = pipeline('summarization', model=model, tokenizer=tokenizer, max_length=500, min_length=70)

def extract_text_pdfplumber(file_path, page_number=0):
    text = ""
    with pdfplumber.open(file_path) as pdf:
        page = pdf.pages[page_number]
        text = page.extract_text()
    return text

def extract_text_from_images(page):
    text = ""
    image_list = page.get_images(full=True)
    for img_ref in image_list:
        xref = img_ref[0]
        base_image = page.get_pixmap(xref=xref)
        img = Image.open(io.BytesIO(base_image.tobytes()))
        text += pytesseract.image_to_string(img)
    return text

def extract_text_ocr(file_path, page_number=0):
    doc = fitz.open(file_path)
    text = ""
    page = doc[page_full]
    text += page.get_text()
    text += extract_text_from_images(page)
    return text

def summarize_text(text):
    if len(text.strip()) == 0:  # If no text extracted, skip summarization
        return "No text extracted from this page."
    summary = summarizer(text, max_length=150, min_length=40, do_sample=False)
    return summary[0]['summary_text']

# Main function for one page
def summarize_one_page(file_path, page_number=0):
    # Extract text using both methods
    text = extract_text_pdfplumber(file_path, page_number) + extract_text_ocr(file_path, page_number)
    # Summarize the extracted text
    summary = summarize_text(text)
    return summary

# Example usage
file_path = 'path_to_JD_letter.pdf'
page_summary = summarize_one_page(file_path, page_number=0)
print("Summary for Page 1:", page_summary)






def chunk_text(text, max_length=500):
    # Tokenize the text and split into chunks that do not exceed max_length
    tokens = tokenizer.tokenize(text)
    chunks = []
    current_chunk = []
    current_length = 0
    for token in tokens:
        current_chunk.append(token)
        current_length += 1
        if current_length >= max_length:
            chunks.append(tokenizer.convert_tokens_to_string(current_chunk))
            current_chunk = []
            current_length = 0
    if current_chunk:  # Append the last chunk if any
        chunks.append(tokenizer.convert_tokens_to_string(current_chunk))
    return chunks

def summarize_text(text):
    chunks = chunk_text(text, max_length=500)  # Adjust the max_length as needed
    summaries = []
    for chunk in chunks:
        inputs = tokenizer.encode("summarize: " + chunk, return_tensors="pt", truncation=True, max_length=512)
        inputs = inputs.to(next(model.parameters()).device)  # Move inputs to the same device as model
        outputs = model.generate(inputs, max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)
        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
        summaries.append(summary)
    return " ".join(summaries)


model = model.to("cuda" if torch.cuda.is_available() else "cpu")

def process_document(file_path, page_number=0):
    text = extract_text_pdfplumber(file_path, page_number) + extract_text_ocr(file_path, page_number)
    summary = summarize_text(text)
    return summary

# Example usage
file_path = 'path_to_JD_letter.pdf'
document_summary = process_document(file_path)
print("Document Summary:", document_app)



