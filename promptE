import pandas as pd

# Sample DataFrame
data = {
    'column1': ['regulation and compliance', 'finance report', 'investment law', 'loan details'],
    'column2': ['risk analysis', 'banking regulation', 'market trends', 'financial law'],
    'column3': ['summary of findings', 'report details', 'document review', 'law and policy'],
    'country': ['USA', 'UK', 'Canada', 'Australia'],
    'business_impact': ['High', 'Medium', 'Low', 'Medium']
}
df = pd.DataFrame(data)

# Keywords to search for
keywords = ['regulation', 'compliance', 'law']

# Additional filters
country_text = 'UK'
business_impact = 'Medium'

# Combine all columns into a single string for each row
combined_columns = df.apply(lambda x: ' '.join(x.astype(str).str.lower()), axis=1)

# Check if any keyword is in the combined string
keyword_pattern = '|'.join(keywords)
keyword_filtered_df = df[combined_columns.str.contains(keyword_pattern, na=False)]

# Filter based on country_text if provided, otherwise fill with None
if country_text:
    country_filtered_df = keyword_filtered_df[keyword_filtered_df['country'] == country_text]
else:
    country_filtered_df = keyword_filtered_df.copy()
    country_filtered_df['country'] = None

# Filter based on business_impact if provided
if business_impact:
    final_filtered_df = country_filtered_df[country_filtered_df['business_impact'] == business_impact]
else:
    final_filtered_df = country_filtered_df.copy()
    final_filtered_df['business_impact'] = None

print(final_filtered_df)




import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util

# Load the data into a DataFrame
df = pd.read_csv('path_to_your_file.csv')  # Adjust this line to load your data
text_column = 'text_column'  # Replace with the actual name of your text column

# Initialize the model
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# Define batch size
batch_size = 1000

# Function to process and get embeddings in batches
def batch_encode_texts(texts, model, batch_size=32):
    embeddings = []
    for start in range(0, len(texts), batch_size):
        end = min(start + batch_size, len(texts))
        batch_texts = texts[start:end]
        batch_embeddings = model.encode(batch_texts, convert_to_tensor=True)
        embeddings.extend(batch_embeddings.cpu().numpy())
    return np.array(embeddings)

# Get embeddings for all texts in the DataFrame
embeddings = batch_encode_texts(df[text_column].tolist(), model, batch_size)

# Save the embeddings to a numpy file for faster access later
np.save('embeddings.npy', embeddings)

# Function to perform semantic search
def semantic_search(query, embeddings, model, df, top_k=5):
    query_embedding = model.encode(query, convert_to_tensor=True)
    cos_scores = util.pytorch_cos_sim(query_embedding, embeddings).numpy().flatten()
    top_results = np.argpartition(-cos_scores, range(top_k))[:top_k]
    return df.iloc[top_results]

# Example usage
query = "Sample query text"
top_k_results = semantic_search(query, embeddings, model, df, top_k=5)
print(top_k_results)


import openai
import pandas as pd
import numpy as np

# Load your OpenAI API key
openai.api_key = 'your_openai_api_key'  # Replace with your actual API key

# Load the data into a DataFrame
df = pd.read_csv('path_to_your_file.csv')  # Adjust this line to load your data
text_column = 'text_column'  # Replace with the actual name of your text column

# Define a function to get embeddings using OpenAI API
def get_embedding(text, model="text-embeddings-002"):
    response = openai.Embedding.create(input=text, model=model)
    return response['data'][0]['embedding']

# Define batch size
batch_size = 100

# Function to process and get embeddings in batches
def batch_encode_texts(texts, batch_size=32):
    embeddings = []
    for start in range(0, len(texts), batch_size):
        end = min(start + batch_size, len(texts))
        batch_texts = texts[start:end]
        batch_embeddings = [get_embedding(text) for text in batch_texts]
        embeddings.extend(batch_embeddings)
    return np.array(embeddings)

# Get embeddings for all texts in the DataFrame
embeddings = batch_encode_texts(df[text_column].tolist(), batch_size)

# Save the embeddings to a numpy file for faster access later
np.save('embeddings.npy', embeddings)

# Function to perform semantic search
def semantic_search(query, embeddings, df, top_k=5):
    query_embedding = np.array(get_embedding(query))
    cos_scores = np.dot(embeddings, query_embedding) / (np.linalg.norm(embeddings, axis=1) * np.linalg.norm(query_embedding))
    top_results = np.argpartition(-cos_scores, range(top_k))[:top_k]
    return df.iloc[top_results]

# Example usage
query = "Sample query text"
top_k_results = semantic_search(query, embeddings, df, top_k=5)
print(top_k_results)


import pandas as pd
from rank_bm25 import BM25Okapi
import string
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
from transformers import AutoTokenizer, AutoModel
import torch
from sklearn.metrics.pairwise import cosine_similarity

# Sample DataFrame
data = {
    'column1': ['This is a sample text', 'Another example sentence', 'More data in here'],
    'column2': ['Different text example', 'More samples of text', 'Another text entry']
}

df = pd.DataFrame(data)

# Combine the text from different columns into one for each row
df['combined_text'] = df.apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

# Preprocess the text: Lowercase, remove punctuation, and stopwords
def preprocess(text):
    text = text.lower()
    text = ''.join([char for char in text if char not in string.punctuation])
    text = ' '.join([word for word in text.split() if word not in ENGLISH_STOP_WORDS])
    return text

df['processed_text'] = df['combined_text'].apply(preprocess)

# Tokenize the processed texts
tokenized_corpus = [doc.split() for doc in df['processed_text']]
bm25 = BM25Okapi(tokenized_corpus)

# Keywords to search for
keywords = "sample text"
tokenized_keywords = keywords.split()

# Get BM25 scores for each document in the corpus
scores = bm25.get_scores(tokenized_keywords)

# Add the BM25 scores to the DataFrame
df['bm25_score'] = scores

# Load MiniLM model and tokenizer
tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')
model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')

# Function to encode text using MiniLM
def encode(texts):
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        model_output = model(**inputs)
    embeddings = model_output.last_hidden_state.mean(dim=1).numpy()
    return embeddings

# Encode the combined texts in the DataFrame
df['dense_embedding'] = list(encode(df['combined_text'].tolist()))

# Encode the keywords
keyword_embedding = encode([keywords])[0]

# Calculate cosine similarity scores
df['dense_score'] = df['dense_embedding'].apply(lambda x: cosine_similarity([x], [keyword_embedding]).item())

# Normalize the scores
df['bm25_score'] = (df['bm25_score'] - df['bm25_score'].min()) / (df['bm25_score'].max() - df['bm25_score'].min())
df['dense_score'] = (df['dense_score'] - df['dense_score'].min()) / (df['dense_score'].max() - df['dense_score'].min())

# Define weightage
weight_bm25 = 0.5
weight_dense = 0.5

# Calculate combined score
df['combined_score'] = weight_bm25 * df['bm25_score'] + weight_dense * df['dense_score']

# Sort the DataFrame by the combined score in descending order
df_sorted = df.sort_values(by='combined_score', ascending=False)

# Display the sorted DataFrame
print("Combined Scores (Sorted):")
print(df_sorted)



