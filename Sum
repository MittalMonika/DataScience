from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Specify the model name for the smaller variant, which is more manageable for testing
model_name = "google/flan-t5-small"

# Load the tokenizer and model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# Move the model to GPU for faster processing
model = model.to("cuda")

print("Model and tokenizer are loaded and moved to GPU.")
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-small")

tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-small")

inputs = tokenizer("A step by step recipe to make bolognese pasta:", return_tensors="pt")

outputs = model.generate(**inputs)

print(tokenizer.batch_decode(outputs, skip_special_tokens=True))
['Pour a cup of bolognese into a large bowl and add the pasta']


import torch

def summarize_text(text, model, tokenizer, max_length=150):
    # Prepend the prompt to the input text
    input_text = "summarize: " + text
    
    # Encode the text input to tensor
    input_ids = tokenizer.encode(input_text, return_tensors="pt").to(model.device)
    
    # Generate summary output using the model
    with torch.no_grad():
        summary_ids = model.generate(
            input_ids,
            max_length=max_length,
            num_beams=4,
            length_penalty=2.0,
            early_stopping=True
        )
    
    # Decode and return the summary
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

# Example text
sample_text = """
The history of natural language processing (NLP) generally started in the 1950s, although work can be found from earlier periods. 
In 1950, Alan Turing published an article titled "Computing Machinery and Intelligence" which proposed what is now called the Turing test as a criterion of intelligence.
"""

# Call the summarization function
summary = summarize_text(sample, model, tokenizer)
print("Original Text:", sample_text)
print("Summary:", summary)
