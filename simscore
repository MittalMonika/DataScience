from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Data frames (already created)

# Function to calculate weighted similarity
def calculate_weighted_similarity(df1, df2, weights):
    # Combine text columns into a single string for each row
    df1_combined = df1.apply(lambda x: ' '.join(x.astype(str)), axis=1)
    df2_combined = df2.apply(lambda x: ' '.join(x.astype(str)), axis=1)
    
    # TF-IDF Vectorization
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(df1_combined.append(df2_combined))

    # Calculate cosine similarity
    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])
    
    # Calculate weighted score
    weighted_scores = []
    for i, row in df2.iterrows():
        score = 0
        for col, weight in weights.items():
            tfidf_vectorizer = TfidfVectorizer()
            col_tfidf_matrix = tfidf_vectorizer.fit_transform([df1[col][0], row[col]])
            col_similarity = cosine_similarity(col_tfidf_matrix[0:1], col_tfidf_matrix[1:])[0][0]
            score += col_similarity * weight
        weighted_scores.append(score)
    
    return weighted_scores

# Define weights
weights = {
    'Title': 2.0,
    'Description': 1.5,
    'Country': 1.2,
    'Regulation': 1.5
}

# Calculate weighted similarities
weighted_similarities = calculate_weighted_similarity(df1, df2, weights)
df2['Weighted_Similarity'] = weighted_similarities

tools.display_dataframe_to_user(name="Second Data Frame with Weighted Similarity Scores", dataframe=df2)

df2[['ID', 'Title', 'Weighted_Similarity']]
