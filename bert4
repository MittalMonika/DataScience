from transformers import pipeline, T5Tokenizer

# Load the model and tokenizer
model_name = 'google/flan-t5-base'
summarizer = pipeline('summarization', model=model_name, tokenizer=model_name)
tokenizer = T5Tokenizer.from_pretrained(model_name)

def chunk_text(text, chunk_size=512, overlap=200):
    tokens = tokenizer.encode(text)
    chunks = []
    start = 0
    while start < len(tokens):
        end = min(start + chunk_size, len(tokens))
        chunk = tokens[start:end]
        chunks.append(tokenizer.decode(chunk, skip_special_tokens=True))
        start = end - overlap
    return chunks

def summarize_large_text(text, chunk_size=512, overlap=200):
    # Chunking the text with overlap
    chunks = chunk_text(text, chunk_size, overlap)
    
    # Summarize each chunk
    chunk_summaries = [summarizer(chunk, max_length=150, min_length=80)[0]['summary_text'] for chunk in chunks]
    
    # Combine summaries
    combined_summary = " ".join(chunk_summaries)
    
    # Initial refinement of the combined summary
    refined_summary = summarizer(combined_summary, max_length=150, min_length=80)[0]['summary_text']
    
    # Further iterative summarization to condense
    final_summary = summarizer(refined_summary, max_length=100, min_length=50)[0]['summary_text']
    
    return final_summary

# Example usage
text = """
Your full text goes here. Make sure it's clean and well-formatted.
"""

summary = summarize_large_text(text)
print(summary)
